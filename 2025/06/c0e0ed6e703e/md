---
title: r1_8b
date: 2025-6-17-22:00
categories:
  - Deepseek
tags:
---

ç³»ç»Ÿå˜é‡ï¼Œå¯¹ç³»ç»Ÿçš„æ‰€æœ‰è´¦æˆ·ç”Ÿæ•ˆï¼Œæ‚¨å¯ä»¥æ ¹æ®æƒ…å†µè‡ªå·±é€‰ã€‚ç‚¹å‡»æ·»åŠ æ·»åŠ ï¼Œè¾“å…¥å˜é‡åOLLAMA_MODELSï¼Œå˜é‡å€¼è¾“å…¥æ‚¨æ”¾ç½®ollamaæ¨¡å‹çš„æ–°åœ°å€ï¼Œæˆ‘è¿™é‡Œæ”¾åœ¨äº†E:\ollama\models

![](images/254E7FA0-46F1-4144-B913-C7C3E82AFEBA.png)

![](images/E5D4D6BF-5C2F-450B-BF73-B2076752FB89.png)
1. æ‹‰å–æ¨¡å‹

> ollama pull deepseek-r1:8b

2. è¿è¡Œæ¨¡å‹

> ollama run deepseek-r1:8b


### ğŸ” Can I run DeepSeek-R1:8B via Ollama?
Currently, **Ollama does not officially support the DeepSeek-R1 8B model** unless it has been added to their
repository or community-supported list. You should check:
- The [Ollama models page](https://ollama.com/models) for updates.
- Community forums (e.g., GitHub issues) if users have shared custom Docker images/definitions.

---

### ğŸ§ª How to run transformer models like DeepSeek-R1 via Ollama
If the model is supported, you can use this command:

```bash
ollama run deepseek-r1:8b
```

This will:
- Download (if not installed) and load the 8B parameter version of DeepSeek-R1.
- Start a local instance for interactive chat or API access.

---

### ğŸ¤” What is DeepSeek-R1:8B?
DeepSeek-R1 is an advanced transformer language model developed by [æ·±åº¦æ±‚ç´¢ï¼ˆDeepSeekï¼‰
](https://www.deepseek.com/). The "8B" refers to **8 billion parameters** in the model. Itâ€™s designed for:
- Natural language understanding and generation.
- Code-related tasks (syntax, debugging).
- Knowledge answering.
- Creative writing.

---

### ğŸ“„ Example usage with Ollama CLI
```bash
# Start interactive chat (if supported)
ollama chat deepseek-r1:8b

# Or generate text via API/command line:
curl http://localhost:11434/api/generate \
  -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1:8b",
    "prompt": "Explain quantum computing in simple terms.",
    "stream": false
  }'
```

---

### âš ï¸ If the model isnâ€™t supported yet:
You can try running it via Docker (if you have technical access):
```bash
docker run -d --name deepseek-r1 \
  -p 11434:11434 \
  --rm \
  -v ollama_models:/models \
  llamafile/docker-ollama \
  predict DeepSeek-R1 /models/deepseek-r1.tar
```
But note: This may not be officially maintained.

---

### ğŸŒŸ What else can Ollama run?
Oll (a) supports models like:
- Llama, Mistral, Mixtral
- GPT models (via LMSYS)
- Gemma, Phi, CodeLlama
- And many others!

Check the [current list on their website](https://ollama.com/models).

---

Let me know if you'd like help with a specific task using DeepSeek-R1 or another model! ğŸ˜Š